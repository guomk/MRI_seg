{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (dataset.py, line 17)",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/guomukun/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3417\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-bb70fcf2a4c5>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from dataset import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/guomukun/fyp_code/segmentation/MRI_seg/dataset.py\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    for self.\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import nibabel as nib\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IBSRdataset(Dataset):\n",
    "    \"\"\"ISBR Brain Segmentation Dataset\"\"\"\n",
    "    # TODO Now load everything during initialization, should change to lazy loading\n",
    "    def __init__(self, config_file, base_dir='../../data/IBSR_nifti_stripped/processed/', transforms_=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            config_file (string): path to the .json config file.\n",
    "            base_dir (string): path to the base directory storing the processed data and annotation\n",
    "            transform (List[torchvision.transforms]): a list of transformation Objects\n",
    "        \"\"\"\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.config_file = config_file\n",
    "        self.base_dir = base_dir\n",
    "\n",
    "        # read config file\n",
    "        with open(config_file) as f:\n",
    "            dataset = json.load(f)\n",
    "\n",
    "        vox_list = []\n",
    "        for obj in dataset['data']:\n",
    "            vox_list.append((obj['image'], obj['label']))\n",
    "\n",
    "        # print(vox_list)\n",
    "\n",
    "        # read images and labels\n",
    "        img_list = []\n",
    "        label_list = []\n",
    "        for img_dir, label_dir in vox_list:\n",
    "            img_dir = os.path.join(base_dir, img_dir)\n",
    "            label_dir = os.path.join(base_dir, label_dir)\n",
    "\n",
    "            img_list.append(load_nifti(img_dir)[:,:,:,1])\n",
    "            label_list.append(load_nifti(label_dir))\n",
    "        \n",
    "        # print(len(img_list))\n",
    "\n",
    "        self.img_slices = []\n",
    "        self.label_slices = []\n",
    "        for i in range(len(img_list)):\n",
    "            img = img_list[i]\n",
    "            label = label_list[i]\n",
    "            assert img.shape == label.shape\n",
    "            for i in range(img.shape[2]):\n",
    "                # take slices\n",
    "                img_slice = img[:,:,i]\n",
    "                label_slice = label[:,:,i]\n",
    "                if img_slice.min() != img_slice.max() and label_slice.min() != label_slice.max(): # take slices with contents only\n",
    "                    self.img_slices.append(img_slice)\n",
    "                    self.label_slices.append(label_slice)\n",
    "                assert len(self.img_slices) == len(self.label_slices)\n",
    "        \n",
    "        # print(len(img_slices))\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_slices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img = self.img_slices[idx]\n",
    "        label = self.label_slices[idx]\n",
    "\n",
    "        return {\n",
    "            'image': torch.from_numpy(img).type(torch.FloatTensor),\n",
    "            'mask': torch.from_numpy(label).type(torch.FloatTensor)\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "trainset = IBSRdataset(config_file=\"dataset_train.json\", base_dir='data/IBSR_nifti_stripped/processed')\n",
    "valset = IBSRdataset(config_file=\"dataset_test.json\", base_dir='data/IBSR_nifti_stripped/processed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Dataloader(trainset, batch)"
   ]
  }
 ]
}